import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import io
from contextlib import redirect_stdout

st.set_page_config(page_title="Gemini Chatbot", layout="centered")
st.title("ğŸ¤– Gemini Data Analyst")
st.caption("Prototipo desarrollado por Marcel F. Castro")

# Inicializar estado de sesiÃ³n
if "messages" not in st.session_state:
    st.session_state.messages = []

if "df" not in st.session_state:
    st.session_state.df = None

# Subida de archivo en el sidebar
uploaded_file = st.sidebar.file_uploader("Carga tu archivo CSV o Excel", type=["csv", "xlsx"])

if uploaded_file is not None:
    if uploaded_file.name.endswith(".csv"):
        st.session_state.df = pd.read_csv(uploaded_file)
    else:
        st.session_state.df = pd.read_excel(uploaded_file)

    df = st.session_state.df

    # Mostrar informaciÃ³n bÃ¡sica del archivo cargado
    st.chat_message("assistant").markdown("ğŸ“Š **Datos cargados:**")
    st.chat_message("assistant").markdown(f"ğŸ”¢ **Filas:** {df.shape[0]} | ğŸ“ **Columnas:** {df.shape[1]}")

    st.chat_message("assistant").markdown("ğŸ§¾ **Nombres de columnas:**")
    st.chat_message("assistant").dataframe(pd.DataFrame({"Columnas": df.columns}))

    st.chat_message("assistant").markdown("ğŸ” **Vista previa aleatoria (10 filas):**")
    st.chat_message("assistant").dataframe(df.sample(10))

# Mostrar historial de mensajes
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        if msg.get("is_dataframe"):
            st.dataframe(msg["content"], use_container_width=False)
        elif msg.get("is_plot"):
            st.pyplot(msg["content"])
        else:
            st.markdown(msg["content"])

# Entrada del usuario
prompt = st.chat_input("Escribe tu mensaje o pregunta aquÃ­...")

if prompt:
    # Mostrar mensaje del usuario
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    if st.session_state.df is not None:
        df = st.session_state.df

        # Contexto bÃ¡sico para el modelo
        context = f"Este es un DataFrame llamado df con columnas: {', '.join(df.columns)}. Responde en espaÃ±ol."

        from openai import OpenAI
        client = OpenAI()

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": context},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )

        code = response.choices[0].message.content

        # Mostrar respuesta como cÃ³digo
        with st.chat_message("assistant"):
            st.markdown("```python\n" + code + "\n```")

        # Ejecutar cÃ³digo
        try:
            output = io.StringIO()
            with redirect_stdout(output):
                exec_globals = {"df": df, "pd": pd, "plt": plt, "st": st}
                exec(code, exec_globals)
                result = exec_globals.get("result", None)

            # Mostrar resultados
            if isinstance(result, pd.DataFrame):
                st.markdown("ğŸ“Š **Resultado:**")
                formatted_df = result.copy()
                for col in formatted_df.columns:
                    if formatted_df[col].dtype in ['int64', 'float64']:
                        formatted_df[col] = formatted_df[col].apply(lambda x: f"{x:,}")
                st.dataframe(formatted_df, use_container_width=False)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": result,
                    "is_dataframe": True
                })

            elif isinstance(result, pd.Series):
                st.markdown("ğŸ“Š **Resultado (serie convertida en tabla):**")
                st.dataframe(result.to_frame(), use_container_width=False)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": result.to_frame(),
                    "is_dataframe": True
                })

            elif isinstance(result, (list, dict)):
                st.markdown("ğŸ“Š **Resultado (convertido en tabla):**")
                df_result = pd.DataFrame(result)
                st.dataframe(df_result, use_container_width=False)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": df_result,
                    "is_dataframe": True
                })

            elif 'plt' in code or plt.get_fignums():
                st.markdown("ğŸ“ˆ **GrÃ¡fico generado**")
                st.pyplot(plt.gcf())
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": plt.gcf(),
                    "is_plot": True
                })
                plt.clf()

            elif output.getvalue().strip():
                st.markdown(output.getvalue())
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": output.getvalue().strip()
                })

            else:
                st.markdown("âœ… CÃ³digo ejecutado correctamente pero no se generÃ³ salida visible.")

        except Exception as e:
            st.error(f"âŒ Error al ejecutar el cÃ³digo: {e}")
            st.session_state.messages.append({
                "role": "assistant",
                "content": f"âŒ Error al ejecutar el cÃ³digo: {e}"
            })
    else:
        st.warning("Por favor carga un archivo para analizar tus datos.")
