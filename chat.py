import streamlit as st
import pandas as pd
import google.generativeai as genai
import io
import contextlib
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Configurar la API de Gemini
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
except KeyError:
    st.error("La clave GEMINI_API_KEY no est√° configurada en los Secrets de Streamlit Cloud.")
    st.stop()

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Chatyfile",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos CSS personalizados
st.markdown("""
    <style>
    .stApp {
        background-color: #f0f2f6;
    }
    .header {
        display: flex;
        align-items: center;
        padding: 10px;
        background-color: #1f77b4;
        border-radius: 10px;
    }
    .header img {
        width: 400px; /* Logo m√°s grande */
        margin-right: 20px;
    }
    h1 {
        color: #ffffff;
        font-family: 'Arial', sans-serif;
        margin: 0;
    }
    .css-1d391kg {
        background-color: #ffffff;
        border-right: 2px solid #1f77b4;
    }
    .stButton>button {
        background-color: #ff7f0e;
        color: white;
        border-radius: 5px;
    }
    .footer {
        text-align: center;
        padding: 10px;
        background-color: #1f77b4;
        color: white;
        position: fixed;
        bottom: 0;
        width: 100%;
        border-top: 2px solid #ffffff;
    }
    </style>
""", unsafe_allow_html=True)

# Cabecera con logotipo a la izquierda
st.markdown('<div class="header">', unsafe_allow_html=True)
st.image("logo.jpeg", width=400)  # Logo m√°s grande
st.title("üìÑ Chatyfile")
st.markdown('</div>', unsafe_allow_html=True)

# Bienvenida
st.markdown("""
    <h3 style='text-align: center; color: #1f77b4;'>¬°Bienvenido a Chatyfile!</h3>
    <p style='text-align: center;'>Sube tu archivo y haz preguntas sobre tus datos</p>
""", unsafe_allow_html=True)

# Barra lateral
with st.sidebar:
    st.header("ü§ñ Opciones")
    uploaded_file = st.file_uploader("Sube tu archivo", type=["csv"])
    st.markdown("---")
    st.subheader("‚ö†Ô∏è Instrucciones")
    st.write("1. Sube el archivo con tus datos.")
    st.write("2. Escribe tu pregunta y presiona 'Enter' o haz clic en 'Enviar'.")
    st.write("3. Escribe 'salir' para finalizar.")

# Pie de p√°gina
st.markdown("""
    <div class="footer">
        <p>¬© 2025 Chatyfile. Todos los derechos reservados. Propiedad intelectual protegida.</p>
    </div>
""", unsafe_allow_html=True)

# Inicializar estado de la sesi√≥n
if "chat" not in st.session_state:
    st.session_state.chat = None
    st.session_state.history = []

# L√≥gica principal de la app
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success("‚úÖ Archivo cargado correctamente.")
    
    # Resumen del archivo
    num_rows, num_cols = df.shape
    st.write("**Resumen del archivo:**")
    st.write(f"- N√∫mero de filas: {num_rows}")
    st.write(f"- N√∫mero de columnas: {num_cols}")
    st.write("**Nombres de las columnas:**")
    st.table(pd.DataFrame(df.columns, columns=["Columnas"]))

    # Inicializar el modelo y el chat si no est√° inicializado
    if st.session_state.chat is None:
        model = genai.GenerativeModel('gemini-2.0-flash')
        st.session_state.chat = model.start_chat(history=[
            {
                "role": "user",
                "parts": ["Tienes un DataFrame de pandas llamado df. Estas son las columnas reales que contiene: " + ", ".join(df.columns) + ". No traduzcas ni cambies ning√∫n nombre de columna. Usa los nombres tal como est√°n."]
            },
            {
                "role": "model",
                "parts": ["Entendido. Usar√© los nombres de columna exactamente como los proporcionaste."]
            }
        ])
        st.session_state.history.append("üü¢ Asistente activo. Pregunta lo que quieras sobre tu DataFrame.")
        st.session_state.history.append("‚úèÔ∏è Escribe 'salir' para finalizar.")

    # Mostrar historial de la conversaci√≥n
    for message in st.session_state.history:
        st.write(message)

    # Formulario para la pregunta (se env√≠a con "Enter" o bot√≥n)
    with st.form(key='pregunta_form', clear_on_submit=True):
        pregunta = st.text_input("ü§ñ Pregunta:", key="pregunta_input")
        submitted = st.form_submit_button(label="Enviar", disabled=False)  # Bot√≥n habilitado

    # Procesar la pregunta si se env√≠a el formulario
    if submitted and pregunta:
        if pregunta.lower() == "salir":
            st.session_state.history.append("üëã Adios.")
            st.session_state.chat = None  # Reiniciar el chat
            st.rerun()
        else:
            try:
                prompt = f"""
Tienes un DataFrame de pandas llamado `df` cargado en memoria.
Estas son las columnas reales: {', '.join(df.columns)}.
NO CAMBIES los nombres de las columnas.
NO INTENTES CARGAR EL DATAFRAME CON pd.read_csv, ya est√° cargado como `df`.

Responde a esta pregunta escribiendo solamente el c√≥digo Python que da la respuesta.
Para preguntas sobre productos, como 'urea', usa b√∫squedas flexibles que ignoren may√∫sculas/min√∫sculas (por ejemplo, .str.contains('urea', case=False, na=False)) y consideren variaciones del texto (por ejemplo, 'Urea 46%', 'urea granulada').
Para resultados num√©ricos o tabulares, devuelve un DataFrame o un valor claro.
Para gr√°ficas (barras, l√≠neas, pastel, boxplot, etc.), usa matplotlib o seaborn con un tama√±o de figura adecuado (por ejemplo, figsize=(8, 6)).
Para c√°lculos estad√≠sticos (media, mediana, desviaci√≥n est√°ndar, correlaciones, etc.), devuelve el resultado en un formato claro, preferiblemente como DataFrame.

Pregunta:
{pregunta}
"""
                response = st.session_state.chat.send_message(prompt)
                code = response.text.strip("```python\n").strip("```").strip()
                st.session_state.history.append(f"üìÑ C√≥digo generado:\n{code}")  # Depuraci√≥n temporal

                exec_globals = {
                    "df": df,
                    "pd": pd,
                    "plt": plt,
                    "sns": sns,
                    "np": np
                }
                buffer = io.StringIO()

                with contextlib.redirect_stdout(buffer):
                    try:
                        exec(code, exec_globals)
                    except Exception as e:
                        st.session_state.history.append(f"‚ùå Error al ejecutar el c√≥digo: {str(e)}")
                        st.rerun()

                output = buffer.getvalue().strip()

                # Mostrar resultados de forma amigable
                if "plt" in code or "sns" in code:
                    # Mostrar gr√°fica si el c√≥digo genera una
                    st.pyplot(plt.gcf())
                    plt.clf()  # Limpiar la figura para la pr√≥xima gr√°fica
                elif output:
                    # Mostrar salida de texto como tabla si es un valor simple
                    st.table(pd.DataFrame({"Resultado": [output]}))
                else:
                    # Intentar mostrar un DataFrame si el c√≥digo lo genera
                    for key, value in exec_globals.items():
                        if isinstance(value, pd.DataFrame) and key != "df":
                            st.dataframe(value)
                            break
                    else:
                        st.session_state.history.append("‚úÖ C√≥digo ejecutado sin salida.")

            except Exception as e:
                st.session_state.history.append(f"‚ùå Error al procesar o ejecutar: {str(e)}")

        st.rerun()  # Refrescar la p√°gina para mostrar el historial actualizado
else:
    st.warning("Por favor, sube un archivo para continuar.")
