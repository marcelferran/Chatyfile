import streamlit as st
import pandas as pd
import google.generativeai as genai
import io
import contextlib
import matplotlib.pyplot as plt
import seaborn as sns

# Configurar la API de Gemini
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
except KeyError:
    st.error("La clave GEMINI_API_KEY no est√° configurada en los Secrets de Streamlit Cloud.")
    st.stop()

# Configuraci√≥n de la p√°gina (sin cambios)
st.set_page_config(
    page_title="Chatyfile",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos CSS personalizados (sin cambios)
st.markdown("""
    <style>
    /* ... tus estilos CSS ... */
    </style>
""", unsafe_allow_html=True)

# Cabecera (sin cambios)
st.markdown('<div class="header">', unsafe_allow_html=True)
st.image("logo.jpeg", width=400)
st.title("üìÑ Chatyfile")
st.markdown('</div>', unsafe_allow_html=True)

# Bienvenida (sin cambios)
st.markdown("""
    <h3 style='text-align: center; color: #1f77b4;'>¬°Bienvenido a Chatyfile!</h3>
    <p style='text-align: center;'>Sube tu archivo y haz preguntas sobre tus datos</p>
""", unsafe_allow_html=True)

# Barra lateral (sin cambios)
with st.sidebar:
    st.header("ü§ñ Opciones")
    uploaded_file = st.file_uploader("Sube tu archivo", type=["csv"])
    st.markdown("---")
    st.subheader("‚ö†Ô∏è Instrucciones")
    st.write("1. Sube el archivo con tus datos.")
    st.write("2. Escribe tu pregunta y presiona 'Enter' o haz clic en 'Enviar'.")
    st.write("3. Escribe 'salir' para finalizar.")

# Pie de p√°gina (sin cambios)
st.markdown("""
    <div class="footer">
        <p>¬© 2025 Chatyfile. Todos los derechos reservados. Propiedad intelectual protegida.</p>
    </div>
""", unsafe_allow_html=True)

# Inicializar estado de la sesi√≥n (sin cambios)
if "chat" not in st.session_state:
    st.session_state.chat = None
    st.session_state.history = []

# L√≥gica principal de la app
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success("‚úÖ Archivo cargado correctamente.")

    # Resumen del archivo (sin cambios)
    num_rows, num_cols = df.shape
    st.write("**Resumen del archivo:**")
    st.write(f"- N√∫mero de filas: {num_rows}")
    st.write(f"- N√∫mero de columnas: {num_cols}")
    st.write("**Nombres de las columnas:**")
    st.table(pd.DataFrame(df.columns, columns=["Columnas"]))

    # Inicializar el modelo y el chat si no est√° inicializado
    if st.session_state.chat is None:
        model = genai.GenerativeModel('gemini-2.0-flash')
        st.session_state.chat = model.start_chat(history=[
            {
                "role": "user",
                "parts": ["Tienes un DataFrame de pandas llamado df. Estas son las columnas reales que contiene: " + ", ".join(df.columns) + ". No traduzcas ni cambies ning√∫n nombre de columna. Usa los nombres tal como est√°n."]
            },
            {
                "role": "model",
                "parts": ["Entendido. Usar√© los nombres de columna exactamente como los proporcionaste."]
            }
        ])
        st.session_state.history.append("üü¢ Asistente activo. Pregunta lo que quieras sobre tu DataFrame.")
        st.session_state.history.append("‚úèÔ∏è Escribe 'salir' para finalizar.")

    # Mostrar historial de la conversaci√≥n
    for message in st.session_state.history:
        st.write(message)

    # Formulario para la pregunta
    with st.form(key='pregunta_form', clear_on_submit=True):
        pregunta = st.text_input("ü§ñ Pregunta:", key="pregunta_input")
        submitted = st.form_submit_button(label="Enviar", disabled=False)

    # Procesar la pregunta si se env√≠a el formulario
    if submitted and pregunta:
        if pregunta.lower() == "salir":
            st.session_state.history.append("üëã Adios.")
            st.session_state.chat = None
            st.rerun()
        else:
            try:
                prompt = f"""
Tienes un DataFrame de pandas llamado `df` cargado en memoria.
Estas son las columnas reales: {', '.join(df.columns)}.
NO CAMBIES los nombres de las columnas.

Responde a la siguiente pregunta de forma amigable y legible.
Si es necesario mostrar datos, genera **√∫nicamente** el c√≥digo Python para hacerlo usando Streamlit (`st.table()`, `st.dataframe()`, `st.metric()`, `st.write()`) y/o Matplotlib/Seaborn (`plt.show()`). Aseg√∫rate de que el c√≥digo sea completo y ejecutable.

**Importante:** Tu respuesta de texto debe explicar los resultados o la acci√≥n realizada. **EVITA incluir bloques de c√≥digo Python completos en tu respuesta de texto.** Solo menciona que se mostrar√° una tabla, un gr√°fico, una m√©trica, etc.

Pregunta:
{pregunta}
"""
                response = st.session_state.chat.send_message(prompt)
                full_response = response.text.strip()
                st.session_state.history.append(f"ü§ñ Chatyfile: {full_response}")

                code = ""
                # Buscar bloques de c√≥digo en la respuesta (m√°s robusto)
                code_blocks = [part.text for part in response.parts if isinstance(part, genai.types.Part.from_dict({"text": ""}).__class__)]
                if code_blocks:
                    code = code_blocks[0].strip("```python\n").strip("```").strip()
                    st.session_state.history.append(f"ü§ñ C√≥digo generado por la IA:") # Para depuraci√≥n
                    st.code(code) # Mostrar el c√≥digo generado (temporalmente para depuraci√≥n)

                exec_globals = {"df": df, "pd": pd, "plt": plt, "sns": sns, "st": st}
                buffer = io.StringIO()
                output = None
                error = None
                plot_generated = False

                with contextlib.redirect_stdout(buffer):
                    try:
                        exec(code, exec_globals)
                        output = buffer.getvalue()
                        if 'plt' in exec_globals and hasattr(exec_globals['plt'], '_Gcf') and exec_globals['plt']._Gcf.get_active():
                            plot_generated = True
                    except Exception as e:
                        error = str(e)

                st.session_state.history.append(f"ü§ñ Ejecuci√≥n del c√≥digo:") # Para depuraci√≥n
                if output:
                    st.session_state.history.append(f"Salida (print): {output}") # Para depuraci√≥n
                if error:
                    st.session_state.history.append(f"Error al ejecutar el c√≥digo: {error}") # Para depuraci√≥n

                if plot_generated:
                    st.pyplot(exec_globals['plt'])
                # No necesitamos mostrar output aqu√≠, se espera que st.write en el c√≥digo generado lo haga

            except Exception as e:
                st.session_state.history.append(f"‚ùå Error general al procesar: {str(e)}")

        st.rerun()
else:
    st.warning("Por favor, sube un archivo para continuar.")
